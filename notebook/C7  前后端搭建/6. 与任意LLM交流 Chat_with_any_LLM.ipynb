{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7cf53b5",
   "metadata": {
    "height": 30
   },
   "source": [
    "# ç¬¬å…­ç«  Gradio çš„ä»‹ç»ä¸å‰ç«¯ç•Œé¢çš„æ­å»º ğŸ’¬"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ce5955",
   "metadata": {
    "height": 30
   },
   "source": [
    "Gradio æ˜¯ä¸€ç§å¿«é€Ÿä¾¿æ·çš„æ–¹æ³•ï¼Œå¯ä»¥ç›´æ¥åœ¨ **Python ä¸­é€šè¿‡å‹å¥½çš„ Web ç•Œé¢æ¼”ç¤ºæœºå™¨å­¦ä¹ æ¨¡å‹**ã€‚åœ¨æœ¬è¯¾ç¨‹ä¸­ï¼Œæˆ‘ä»¬å°†å­¦ä¹ *å¦‚ä½•ä½¿ç”¨å®ƒä¸ºç”Ÿæˆå¼äººå·¥æ™ºèƒ½åº”ç”¨ç¨‹åºæ„å»ºç”¨æˆ·ç•Œé¢*ã€‚åœ¨æ„å»ºäº†åº”ç”¨ç¨‹åºçš„æœºå™¨å­¦ä¹ æˆ–ç”Ÿæˆå¼äººå·¥æ™ºèƒ½åï¼Œå¦‚æœä½ æƒ³æ„å»ºä¸€ä¸ªdemoç»™å…¶ä»–äººçœ‹ï¼Œä¹Ÿè®¸æ˜¯ä¸ºäº†è·å¾—åé¦ˆå¹¶æ¨åŠ¨ç³»ç»Ÿçš„æ”¹è¿›ï¼Œæˆ–è€…åªæ˜¯å› ä¸ºä½ è§‰å¾—è¿™ä¸ªç³»ç»Ÿå¾ˆé…·ï¼Œæ‰€ä»¥æƒ³æ¼”ç¤ºä¸€ä¸‹ï¼šGradio å¯ä»¥è®©æ‚¨é€šè¿‡ Python æ¥å£ç¨‹åºå¿«é€Ÿå®ç°è¿™ä¸€ç›®æ ‡ï¼Œè€Œæ— éœ€ç¼–å†™ä»»ä½•å‰ç«¯ã€ç½‘é¡µæˆ– JavaScript ä»£ç ã€‚\n",
    "åŠ è½½ HF API å¯†é’¥å’Œç›¸å…³ Python åº“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a09f0255",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['ZHIPUAI_API_KEY'] ='99ee3e4eb4477848c7a44c0e154a9018.3a7bL4l15TkF3wPi'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fa6fa00-6bd1-4839-bcaf-8bae9267ee79",
   "metadata": {
    "height": 199
   },
   "outputs": [],
   "source": [
    "# å¯¼å…¥å¿…è¦çš„åº“\n",
    "import os                # ç”¨äºæ“ä½œç³»ç»Ÿç›¸å…³çš„æ“ä½œï¼Œä¾‹å¦‚è¯»å–ç¯å¢ƒå˜é‡\n",
    "import io                # ç”¨äºå¤„ç†æµå¼æ•°æ®ï¼ˆä¾‹å¦‚æ–‡ä»¶æµï¼‰\n",
    "import IPython.display   # ç”¨äºåœ¨IPythonç¯å¢ƒä¸­æ˜¾ç¤ºæ•°æ®ï¼Œä¾‹å¦‚å›¾ç‰‡\n",
    "import requests          # ç”¨äºè¿›è¡ŒHTTPè¯·æ±‚ï¼Œä¾‹å¦‚GETå’ŒPOSTè¯·æ±‚\n",
    "import zhipuai\n",
    "from zhipuai_llm import ZhipuAILLM\n",
    "\n",
    "# è®¾ç½®è¯·æ±‚çš„é»˜è®¤è¶…æ—¶æ—¶é—´ä¸º60ç§’\n",
    "requests.adapters.DEFAULT_TIMEOUT = 60\n",
    "\n",
    "# å¯¼å…¥dotenvåº“çš„å‡½æ•°\n",
    "# dotenvå…è®¸æ‚¨ä».envæ–‡ä»¶ä¸­è¯»å–ç¯å¢ƒå˜é‡\n",
    "# è¿™åœ¨å¼€å‘æ—¶ç‰¹åˆ«æœ‰ç”¨ï¼Œå¯ä»¥é¿å…å°†æ•æ„Ÿä¿¡æ¯ï¼ˆå¦‚APIå¯†é’¥ï¼‰ç¡¬ç¼–ç åˆ°ä»£ç ä¸­\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "# å¯»æ‰¾.envæ–‡ä»¶å¹¶åŠ è½½å®ƒçš„å†…å®¹\n",
    "# è¿™å…è®¸æ‚¨ä½¿ç”¨os.environæ¥è¯»å–åœ¨.envæ–‡ä»¶ä¸­è®¾ç½®çš„ç¯å¢ƒå˜é‡\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "# ä»ç¯å¢ƒå˜é‡ä¸­è¯»å–'ZHIPUAI_API_KEY'å¹¶å°†å…¶å­˜å‚¨åœ¨hf_api_keyå˜é‡ä¸­\n",
    "zhipuai.api_key = os.environ['ZHIPUAI_API_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4f627a",
   "metadata": {
    "height": 30
   },
   "source": [
    "æˆ‘ä»¬åœ¨è¿™é‡Œè®¾ç½®tokenå’Œè¾…åŠ©å‡½æ•°ã€‚ä½ å¯ä»¥çœ‹åˆ°ï¼Œåœ¨è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨äº†ä¸åŒçš„åº“ã€‚æˆ‘ä»¬ä½¿ç”¨çš„æ˜¯æ–‡æœ¬ç”Ÿæˆåº“ï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºå¤„ç†å¼€æº LLM çš„ç²¾ç®€åº“ï¼Œå¯ä»¥è®©ä½ åŒæ—¶åŠ è½½ APIï¼ˆå°±åƒæˆ‘ä»¬åœ¨è¿™é‡Œåšçš„ä¸€æ ·ï¼‰ï¼Œä¹Ÿå¯ä»¥åœ¨æœ¬åœ°è¿è¡Œä½ è‡ªå·±çš„ LLMã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "095da8fe-24aa-4dc7-8e08-aa2f949ae21f",
   "metadata": {
    "height": 131
   },
   "outputs": [],
   "source": [
    "# åŠ©æ‰‹å‡½æ•°\n",
    "llm = ZhipuAILLM(model=\"chatglm_std\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d034a95",
   "metadata": {
    "height": 30
   },
   "source": [
    "## å»ºç«‹ä¸€ä¸ªåº”ç”¨ç¨‹åºï¼Œä¸ä»»ä½•LLMèŠå¤©ï¼"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85eeeba",
   "metadata": {
    "height": 30
   },
   "source": [
    "åœ¨ç¬¬ 2 è¯¾ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†ä¸€ä¸ªéå¸¸ç®€å•çš„ Gradio ç•Œé¢ï¼Œå®ƒæœ‰ä¸€ä¸ªæ–‡æœ¬æ¡†è¾“å…¥å’Œä¸€ä¸ªè¾“å‡ºã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥ç”¨ç±»ä¼¼çš„æ–¹å¼ä¸ LLM èŠå¤©ã€‚å†æ¬¡å¤åˆ¶æˆ‘ä»¬çš„promptã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å¯ä»¥å†³å®šéœ€è¦å¤šå°‘tokenã€‚è¿™å°±æ˜¯éå¸¸ç®€å•åœ°å‘ LLM æé—®çš„æ–¹æ³•ã€‚ä½†æˆ‘ä»¬è¿˜æ˜¯ä¸èƒ½èŠå¤©ï¼Œå› ä¸ºå¦‚æœä½ å†é—®ä¸€ä¸ªåç»­é—®é¢˜ï¼Œå®ƒå°±æ— æ³•ç†è§£æˆ–ä¿ç•™ä¸Šä¸‹æ–‡ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc9a9159",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import logging\n",
    "from typing import (\n",
    "    Any,\n",
    "    AsyncIterator,\n",
    "    Dict,\n",
    "    Iterator,\n",
    "    List,\n",
    "    Optional,\n",
    ")\n",
    "\n",
    "from langchain.callbacks.manager import (\n",
    "    AsyncCallbackManagerForLLMRun,\n",
    "    CallbackManagerForLLMRun,\n",
    ")\n",
    "from langchain.llms.base import LLM\n",
    "from langchain.pydantic_v1 import Field, root_validator\n",
    "from langchain.schema.output import GenerationChunk\n",
    "from langchain.utils import get_from_dict_or_env\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class ZhipuAILLM(LLM):\n",
    "    \"\"\"Zhipuai hosted open source or customized models.\n",
    "\n",
    "    To use, you should have the ``zhipuai`` python package installed, and\n",
    "    the environment variable ``qianfan_ak`` and ``qianfan_sk`` set with\n",
    "    your API key and Secret Key.\n",
    "\n",
    "    ak, sk are required parameters which you could get from\n",
    "    https://cloud.baidu.com/product/wenxinworkshop\n",
    "\n",
    "    Example:\n",
    "        .. code-block:: python\n",
    "\n",
    "            from langchain.llms import QianfanLLMEndpoint\n",
    "            qianfan_model = QianfanLLMEndpoint(model=\"ERNIE-Bot\",\n",
    "                endpoint=\"your_endpoint\", ak=\"your_ak\", sk=\"your_sk\")\n",
    "    \"\"\"\n",
    "\n",
    "    model_kwargs: Dict[str, Any] = Field(default_factory=dict)\n",
    "\n",
    "    client: Any\n",
    "\n",
    "    model: str = \"chatglm_std\"\n",
    "    \"\"\"Model name in chatglm_pro, chatglm_std, chatglm_lite. \"\"\"\n",
    "\n",
    "    zhipuai_api_key: Optional[str] = None\n",
    "\n",
    "    incremental: Optional[bool] = True\n",
    "    \"\"\"Whether to incremental the results or not.\"\"\"\n",
    "\n",
    "    streaming: Optional[bool] = False\n",
    "    \"\"\"Whether to streaming the results or not.\"\"\"\n",
    "    # streaming = -incremental\n",
    "\n",
    "    request_timeout: Optional[int] = 60\n",
    "    \"\"\"request timeout for chat http requests\"\"\"\n",
    "\n",
    "    top_p: Optional[float] = 0.8\n",
    "    temperature: Optional[float] = 0.95\n",
    "    request_id: Optional[float] = None\n",
    "\n",
    "    @root_validator()\n",
    "    def validate_enviroment(cls, values: Dict) -> Dict:\n",
    "        values[\"zhipuai_api_key\"] = get_from_dict_or_env(\n",
    "            values,\n",
    "            \"zhipuai_api_key\",\n",
    "            \"ZHIPUAI_API_KEY\",\n",
    "        )\n",
    "\n",
    "        params = {\n",
    "            \"api_key\": values[\"zhipuai_api_key\"],\n",
    "            \"model\": values[\"model\"],\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            import zhipuai\n",
    "\n",
    "            values[\"client\"] = zhipuai.model_api\n",
    "        except ImportError:\n",
    "            raise ValueError(\n",
    "                \"zhipuai package not found, please install it with \"\n",
    "                \"`pip install zhipuai`\"\n",
    "            )\n",
    "        return values\n",
    "\n",
    "    @property\n",
    "    def _identifying_params(self) -> Dict[str, Any]:\n",
    "        return {\n",
    "            **{\"model\": self.model},\n",
    "            **super()._identifying_params,\n",
    "        }\n",
    "\n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        \"\"\"Return type of llm.\"\"\"\n",
    "        return \"zhipuai\"\n",
    "\n",
    "    @property\n",
    "    def _default_params(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get the default parameters for calling OpenAI API.\"\"\"\n",
    "        normal_params = {\n",
    "            \"streaming\" :self.streaming,\n",
    "            \"top_p\": self.top_p,\n",
    "            \"temperature\": self.temperature,\n",
    "            \"request_id\": self.request_id,\n",
    "        }\n",
    "\n",
    "        return {**normal_params, **self.model_kwargs}\n",
    "\n",
    "    def _convert_prompt_msg_params(\n",
    "        self,\n",
    "        prompt: str,\n",
    "        **kwargs: Any,\n",
    "    ) -> dict:\n",
    "        return {\n",
    "            **{\"prompt\": prompt, \"model\": self.model},\n",
    "            **self._default_params,\n",
    "            **kwargs,\n",
    "        }\n",
    "\n",
    "    def _call(\n",
    "        self,\n",
    "        prompt: str,\n",
    "        stop: Optional[List[str]] = None,\n",
    "        run_manager: Optional[CallbackManagerForLLMRun] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> str:\n",
    "        \"\"\"Call out to an zhipuai models endpoint for each generation with a prompt.\n",
    "        Args:\n",
    "            prompt: The prompt to pass into the model.\n",
    "        Returns:\n",
    "            The string generated by the model.\n",
    "\n",
    "        Example:\n",
    "            .. code-block:: python\n",
    "                response = zhipuai_model(\"Tell me a joke.\")\n",
    "        \"\"\"\n",
    "        if self.streaming:\n",
    "            completion = \"\"\n",
    "            for chunk in self._stream(prompt, stop, run_manager, **kwargs):\n",
    "                completion += chunk.text\n",
    "            return completion\n",
    "        params = self._convert_prompt_msg_params(prompt, **kwargs)\n",
    "        response_payload = self.client.invoke(**params)\n",
    "\n",
    "        print(response_payload)\n",
    "        return response_payload[\"data\"][\"choices\"][-1][\"content\"]\n",
    "\n",
    "    async def _acall(\n",
    "        self,\n",
    "        prompt: str,\n",
    "        stop: Optional[List[str]] = None,\n",
    "        run_manager: Optional[AsyncCallbackManagerForLLMRun] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> str:\n",
    "        if self.streaming:\n",
    "            completion = \"\"\n",
    "            async for chunk in self._astream(prompt, stop, run_manager, **kwargs):\n",
    "                completion += chunk.text\n",
    "            return completion\n",
    "\n",
    "        params = self._convert_prompt_msg_params(prompt, **kwargs)\n",
    "        response = await self.client.async_invoke(**params)\n",
    "\n",
    "        return response_payload\n",
    "\n",
    "    def _stream(\n",
    "        self,\n",
    "        prompt: str,\n",
    "        stop: Optional[List[str]] = None,\n",
    "        run_manager: Optional[CallbackManagerForLLMRun] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> Iterator[GenerationChunk]:\n",
    "        params = self._convert_prompt_msg_params(prompt, **kwargs)\n",
    "\n",
    "        for res in self.client.invoke(**params):\n",
    "            if res:\n",
    "                chunk = GenerationChunk(text=res)\n",
    "                yield chunk\n",
    "                if run_manager:\n",
    "                    run_manager.on_llm_new_token(chunk.text)\n",
    "\n",
    "    async def _astream(\n",
    "\n",
    "        self,\n",
    "        prompt: str,\n",
    "        stop: Optional[List[str]] = None,\n",
    "        run_manager: Optional[AsyncCallbackManagerForLLMRun] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> AsyncIterator[GenerationChunk]:\n",
    "        params = self._convert_prompt_msg_params(prompt, **kwargs)\n",
    "\n",
    "        async for res in await self.client.ado(**params):\n",
    "            if res:\n",
    "                chunk = GenerationChunk(text=res[\"data\"][\"choices\"][\"content\"])\n",
    "\n",
    "                yield chunk\n",
    "                if run_manager:\n",
    "                    await run_manager.on_llm_new_token(chunk.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a362085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'code': 200, 'msg': 'æ“ä½œæˆåŠŸ', 'data': {'request_id': '7982261728276681250', 'task_id': '7982261728276681250', 'task_status': 'SUCCESS', 'choices': [{'role': 'assistant', 'content': '\" NIHï¼ˆNational Institutes of Healthï¼Œç¾å›½å›½ç«‹å«ç”Ÿç ”ç©¶é™¢ï¼‰æ˜¯ç¾å›½æ”¿åºœæ——ä¸‹çš„ä¸€ä¸ªæœºæ„ï¼Œä¸»è¦è´Ÿè´£ç”Ÿç‰©åŒ»å­¦ç ”ç©¶å’Œå…¬å…±å«ç”Ÿé¢†åŸŸçš„æ”¯æŒå’Œç®¡ç†ã€‚å®ƒæˆç«‹äº 1870 å¹´ï¼Œæ€»éƒ¨ä½äºç¾å›½é©¬é‡Œå…°å·è´å¡æ–¯è¾¾å¸‚ã€‚\\\\n\\\\nNIH ä¸»è¦ç”± 27 ä¸ªç ”ç©¶æ‰€å’Œä¸­å¿ƒç»„æˆï¼Œå…¶ä¸­åŒ…æ‹¬ç¾å›½å›½å®¶ç™Œç—‡ç ”ç©¶æ‰€ã€ç¾å›½å›½å®¶å¿ƒè¡€ç®¡ç—…ç ”ç©¶æ‰€ã€ç¾å›½å›½ç«‹ç³–å°¿ç—…ã€æ¶ˆåŒ–å’Œè‚¾è„ç—…ç ”ç©¶æ‰€ç­‰ã€‚å®ƒä¸»è¦è´Ÿè´£èµ„åŠ©ç”Ÿç‰©åŒ»å­¦ç ”ç©¶ï¼Œä¿ƒè¿›å…¬å…±å¥åº·å’ŒåŒ»ç–—æ°´å¹³çš„æé«˜ã€‚åŒæ—¶ï¼ŒNIH ä¹Ÿè´Ÿè´£ç›‘ç®¡å’ŒæŒ‡å¯¼ç”Ÿç‰©åŒ»å­¦ç ”ç©¶çš„è¡Œä¸ºå’Œä¼¦ç†ï¼Œç¡®ä¿ç ”ç©¶çš„å¯é æ€§å’Œå…¬æ­£æ€§ã€‚\\\\n\\\\nåœ¨ 2023 å¹´ï¼ŒNIH çš„é¢„ç®—çº¦ä¸º 47 äº¿ç¾å…ƒï¼Œæ˜¯å…¨çƒæœ€å¤§çš„ç”Ÿç‰©åŒ»å­¦ç ”ç©¶èµ„é‡‘æä¾›è€…ä¹‹ä¸€ã€‚å®ƒçš„ç ”ç©¶æˆæœå¹¿æ³›åº”ç”¨äºä¸´åºŠå®è·µå’Œå…¬å…±å¥åº·é¢†åŸŸï¼Œå¯¹å…¨çƒåŒ»ç–—å¥åº·æ°´å¹³çš„æé«˜åšå‡ºäº†é‡è¦è´¡çŒ®ã€‚\"'}], 'usage': {'prompt_tokens': 137, 'completion_tokens': 177, 'total_tokens': 314}}, 'success': True}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\" NIHï¼ˆNational Institutes of Healthï¼Œç¾å›½å›½ç«‹å«ç”Ÿç ”ç©¶é™¢ï¼‰æ˜¯ç¾å›½æ”¿åºœæ——ä¸‹çš„ä¸€ä¸ªæœºæ„ï¼Œä¸»è¦è´Ÿè´£ç”Ÿç‰©åŒ»å­¦ç ”ç©¶å’Œå…¬å…±å«ç”Ÿé¢†åŸŸçš„æ”¯æŒå’Œç®¡ç†ã€‚å®ƒæˆç«‹äº 1870 å¹´ï¼Œæ€»éƒ¨ä½äºç¾å›½é©¬é‡Œå…°å·è´å¡æ–¯è¾¾å¸‚ã€‚\\\\n\\\\nNIH ä¸»è¦ç”± 27 ä¸ªç ”ç©¶æ‰€å’Œä¸­å¿ƒç»„æˆï¼Œå…¶ä¸­åŒ…æ‹¬ç¾å›½å›½å®¶ç™Œç—‡ç ”ç©¶æ‰€ã€ç¾å›½å›½å®¶å¿ƒè¡€ç®¡ç—…ç ”ç©¶æ‰€ã€ç¾å›½å›½ç«‹ç³–å°¿ç—…ã€æ¶ˆåŒ–å’Œè‚¾è„ç—…ç ”ç©¶æ‰€ç­‰ã€‚å®ƒä¸»è¦è´Ÿè´£èµ„åŠ©ç”Ÿç‰©åŒ»å­¦ç ”ç©¶ï¼Œä¿ƒè¿›å…¬å…±å¥åº·å’ŒåŒ»ç–—æ°´å¹³çš„æé«˜ã€‚åŒæ—¶ï¼ŒNIH ä¹Ÿè´Ÿè´£ç›‘ç®¡å’ŒæŒ‡å¯¼ç”Ÿç‰©åŒ»å­¦ç ”ç©¶çš„è¡Œä¸ºå’Œä¼¦ç†ï¼Œç¡®ä¿ç ”ç©¶çš„å¯é æ€§å’Œå…¬æ­£æ€§ã€‚\\\\n\\\\nåœ¨ 2023 å¹´ï¼ŒNIH çš„é¢„ç®—çº¦ä¸º 47 äº¿ç¾å…ƒï¼Œæ˜¯å…¨çƒæœ€å¤§çš„ç”Ÿç‰©åŒ»å­¦ç ”ç©¶èµ„é‡‘æä¾›è€…ä¹‹ä¸€ã€‚å®ƒçš„ç ”ç©¶æˆæœå¹¿æ³›åº”ç”¨äºä¸´åºŠå®è·µå’Œå…¬å…±å¥åº·é¢†åŸŸï¼Œå¯¹å…¨çƒåŒ»ç–—å¥åº·æ°´å¹³çš„æé«˜åšå‡ºäº†é‡è¦è´¡çŒ®ã€‚\"'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = ZhipuAILLM(model=\"chatglm_std\")\n",
    "llm.predict(\"nih\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477adf37",
   "metadata": {},
   "source": [
    "### 2.1 å‚æ•°è§£æ\n",
    "\n",
    "- fn=generate: è¿™æ˜¯ç”¨äºå¤„ç†è¾“å…¥çš„å‡½æ•°ï¼Œå³æ–‡æœ¬ç”Ÿæˆå‡½æ•° generateã€‚\n",
    "- inputs=[\n",
    "        gr.Textbox(label=\"Prompt\"),\n",
    "        gr.Slider(label=\"Temperature\", value=0,  maximum=1, minimum=0)ã€‚\n",
    "    ]: è¿™å®šä¹‰äº†æ¨¡å‹çš„è¾“å…¥ã€‚\n",
    "    ä½¿ç”¨ gr.Textbox éƒ¨ä»¶æ¥ä»¥æ–‡æœ¬æ¡†çš„å½¢å¼æ˜¾ç¤ºè¾“å…¥çš„å†…å®¹æè¿°ï¼Œlabel å‚æ•°è®¾ç½®äº†è¾“å…¥éƒ¨ä»¶çš„æ ‡ç­¾ä¸º promptã€‚\n",
    "    ä½¿ç”¨ gr.Slider éƒ¨ä»¶ä»¥æ»‘åŠ¨æ¡çš„å½¢å¼æ¥æ˜¾ç¤ºè¾“å…¥çš„å†…å®¹æè¿°ï¼Œlabel å‚æ•°è®¾ç½®äº†è¾“å…¥éƒ¨ä»¶çš„æ ‡ç­¾ä¸º temperatureã€‚\n",
    "- outputs=[gr.Textbox(label=\"Caption\")]: è¿™å®šä¹‰äº†è¾“å‡ºéƒ¨åˆ†ã€‚ä½¿ç”¨ gr.Textbox éƒ¨ä»¶æ¥æ˜¾ç¤ºç”Ÿæˆçš„å†…å®¹æè¿°ï¼Œlabel å‚æ•°è®¾ç½®äº†è¾“å‡ºéƒ¨ä»¶çš„æ ‡ç­¾ã€‚\n",
    "- title=\"Chat Robot\": è¿™æ˜¯ç•Œé¢çš„æ ‡é¢˜ï¼Œå°†æ˜¾ç¤ºåœ¨ç•Œé¢çš„é¡¶éƒ¨ã€‚\n",
    "- description=\"Local Knowledge Base Q&A with llm \": è¿™æ˜¯ç•Œé¢çš„æè¿°ï¼Œæä¾›æœ‰å…³ç•Œé¢åŠŸèƒ½çš„æ›´å¤šä¿¡æ¯ã€‚\n",
    "- allow_flagging=\"never\": è¿™è®¾ç½®äº†ä¸å…è®¸æ ‡è®°å†…å®¹ï¼Œç¡®ä¿ä¸ä¼šæ˜¾ç¤ºæ ‡è®°ä¸æ°å½“å†…å®¹çš„é€‰é¡¹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0dcb659e-b71b-46da-b9d2-6ee62498995f",
   "metadata": {
    "height": 182
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# å¯¼å…¥æ‰€éœ€çš„åº“\n",
    "import gradio as gr  # ç”¨äºåˆ›å»ºWebç•Œé¢\n",
    "import os  # ç”¨äºä¸æ“ä½œç³»ç»Ÿäº¤äº’ï¼Œå¦‚è¯»å–ç¯å¢ƒå˜é‡\n",
    "\n",
    "# å®šä¹‰ä¸€ä¸ªå‡½æ•°æ¥æ ¹æ®è¾“å…¥ç”Ÿæˆæ–‡æœ¬\n",
    "def generate(input, slider):\n",
    "    # ä½¿ç”¨é¢„å®šä¹‰çš„clientå¯¹è±¡çš„generateæ–¹æ³•ï¼Œä»è¾“å…¥ç”Ÿæˆæ–‡æœ¬\n",
    "    # sliderçš„å€¼é™åˆ¶ç”Ÿæˆçš„tokençš„æ•°é‡\n",
    "    output = llm.predict(input, temperature=slider)\n",
    "    return output  # è¿”å›ç”Ÿæˆçš„æ–‡æœ¬\n",
    "\n",
    "# åˆ›å»ºä¸€ä¸ªWebç•Œé¢\n",
    "# è¾“å…¥ï¼šä¸€ä¸ªæ–‡æœ¬æ¡†å’Œä¸€ä¸ªæ»‘å—\n",
    "# è¾“å‡ºï¼šä¸€ä¸ªæ–‡æœ¬æ¡†æ˜¾ç¤ºç”Ÿæˆçš„æ–‡æœ¬\n",
    "demo = gr.Interface(\n",
    "    fn=generate, \n",
    "    inputs=[\n",
    "        gr.Textbox(label=\"Prompt\"),  # æ–‡æœ¬è¾“å…¥æ¡†\n",
    "        gr.Slider(label=\"Temperature\", value=0,  maximum=1, minimum=0)  # æ»‘å—ç”¨äºé€‰æ‹©æ¨¡å‹çš„ temperature\n",
    "    ], \n",
    "    outputs=[gr.Textbox(label=\"Completion\")],  # æ˜¾ç¤ºç”Ÿæˆæ–‡æœ¬çš„æ–‡æœ¬æ¡†\n",
    "    title=\"Chat Robot\",  # ç•Œé¢æ ‡é¢˜\n",
    "    description=\"Local Knowledge Base Q&A with llm\",  # ç•Œé¢æè¿°\n",
    "    # allow_flagging=\"never\", \n",
    ")\n",
    "\n",
    "# å…³é—­å¯èƒ½å·²ç»å¯åŠ¨çš„ä»»ä½•å…ˆå‰çš„gradioå®ä¾‹\n",
    "gr.close_all()\n",
    "\n",
    "# å¯åŠ¨Webç•Œé¢\n",
    "# ä½¿ç”¨ç¯å¢ƒå˜é‡PORT1ä½œä¸ºæœåŠ¡å™¨çš„ç«¯å£å·\n",
    "# demo.launch(share=True, server_port=int(os.environ['PORT1']))\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5f80b1",
   "metadata": {},
   "source": [
    "ç°åœ¨æˆ‘ä»¬å·²ç»æ­å»ºäº†ä¸€ä¸ªéå¸¸ç®€å•çš„ Gradio ç•Œé¢ï¼Œå®ƒæœ‰ä¸€ä¸ªæ–‡æœ¬æ¡†è¾“å…¥å’Œä¸€ä¸ªè¾“å‡ºã€‚æˆ‘ä»¬å·²ç»å¯ä»¥éå¸¸ç®€å•åœ°å‘ LLM æé—®ã€‚ä½†æˆ‘ä»¬è¿˜æ˜¯ä¸èƒ½èŠå¤©ï¼Œå› ä¸ºå¦‚æœä½ å†é—®ä¸€ä¸ªåç»­é—®é¢˜ï¼Œå®ƒå°±æ— æ³•ç†è§£æˆ–ä¿ç•™ä¸Šä¸‹æ–‡ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e5b428",
   "metadata": {
    "height": 30
   },
   "source": [
    "å› æ­¤ï¼ŒåŸºæœ¬ä¸Šæˆ‘ä»¬è¦åšçš„æ˜¯ï¼Œå‘æ¨¡å‹å‘é€æˆ‘ä»¬ä¹‹å‰çš„é—®é¢˜ã€å®ƒè‡ªå·±çš„å›ç­”ä»¥åŠåç»­é—®é¢˜ã€‚ä½†å»ºç«‹æ‰€æœ‰è¿™äº›éƒ½æœ‰ç‚¹éº»çƒ¦ã€‚è¿™å°±æ˜¯ Gradio èŠå¤©æœºå™¨äººç»„ä»¶çš„ä½œç”¨æ‰€åœ¨ï¼Œå› ä¸ºå®ƒå…è®¸æˆ‘ä»¬ç®€åŒ–å‘æ¨¡å‹å‘é€å¯¹è¯å†å²è®°å½•çš„è¿‡ç¨‹ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc48b74",
   "metadata": {
    "height": 30
   },
   "source": [
    "å› æ­¤ï¼Œæˆ‘ä»¬è¦è§£å†³è¿™ä¸ªé—®é¢˜ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å°†å¼•å…¥ä¸€ä¸ªæ–°çš„ Gradio ç»„ä»¶--Gradio Chatbotã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1943fd-213a-48bb-966e-e84b9ae255b1",
   "metadata": {},
   "source": [
    "![math](images/ch06_math.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33547d43",
   "metadata": {
    "height": 30
   },
   "source": [
    "## ä½¿ç”¨ `gr.Chatbot()` æ¥åŠ©åŠ›!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83360647",
   "metadata": {
    "height": 30
   },
   "source": [
    "è®©æˆ‘ä»¬å¼€å§‹ä½¿ç”¨ Gradio Chatbot ç»„ä»¶ã€‚è¿™é‡Œå®ä¾‹åŒ–äº†ä¸€ä¸ªå¸¦æœ‰æ–‡æœ¬æ¡†æç¤ºå’Œæäº¤æŒ‰é’®çš„ Gradle ChatBot ç»„ä»¶ï¼Œæ˜¯ä¸€ä¸ªéå¸¸ç®€å•çš„ç”¨æˆ·ç•Œé¢ã€‚ä½†æˆ‘ä»¬ç°åœ¨è¿˜ä¸æ˜¯åœ¨å’Œ LLM èŠå¤©ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c70dcae",
   "metadata": {
    "height": 30
   },
   "source": [
    "åªéœ€éšæœºé€‰æ‹©ä¸‰ä¸ªé¢„è®¾å›å¤ï¼Œç„¶åå°†æˆ‘çš„ä¿¡æ¯å’Œæœºå™¨äººçš„ä¿¡æ¯æ·»åŠ åˆ°èŠå¤©è®°å½•ä¸­ã€‚æ‰€ä»¥åœ¨è¿™é‡Œï¼Œä½ å¯ä»¥çœ‹åˆ°æˆ‘å¯ä»¥è¯´ä»»ä½•è¯ï¼Œå®ƒåŸºæœ¬ä¸Šä¼šéšæœºæŸ¥çœ‹è¿™ä¸‰ä¸ªå›å¤ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0179df18-bad5-430d-a91b-1fb0c972d3ca",
   "metadata": {},
   "source": [
    "![math_with_template](images/ch06_math_with_template.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d932fde-da5e-47f1-959b-86b053bb9a42",
   "metadata": {},
   "source": [
    "æˆ‘ä»¬å¿…é¡»æ ¼å¼åŒ–èŠå¤©promptã€‚æ­¤å¤„æ­£åœ¨å®šä¹‰è¿™ä¸ªæ ¼å¼åŒ–èŠå¤©promptå‡½æ•°ã€‚\n",
    "åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬è¦åšçš„å°±æ˜¯ä½¿å…¶åŒ…å«èŠå¤©å†å²è®°å½•ï¼Œè¿™æ · LLM å°±èƒ½çŸ¥é“ä¸Šä¸‹æ–‡ã€‚\n",
    "ä½†è¿™è¿˜ä¸å¤Ÿã€‚æˆ‘ä»¬è¿˜éœ€è¦å‘Šè¯‰å®ƒï¼Œå“ªäº›ä¿¡æ¯æ¥è‡ªç”¨æˆ·ï¼Œå“ªäº›ä¿¡æ¯æ¥è‡ª LLM æœ¬èº«ï¼Œä¹Ÿå°±æ˜¯æˆ‘ä»¬æ­£åœ¨è°ƒç”¨çš„åŠ©æ‰‹ã€‚\n",
    "å› æ­¤ï¼Œæˆ‘ä»¬è®¾ç½®äº†æ ¼å¼èŠå¤©promptåŠŸèƒ½ï¼Œåœ¨èŠå¤©è®°å½•çš„æ¯ä¸€è½®ä¸­ï¼Œéƒ½åŒ…å«ä¸€æ¡ç”¨æˆ·ä¿¡æ¯å’Œä¸€æ¡åŠ©æ‰‹ä¿¡æ¯ï¼Œä»¥ä¾¿æˆ‘ä»¬çš„æ¨¡å‹èƒ½å‡†ç¡®å›ç­”åç»­é—®é¢˜ã€‚\n",
    "ç°åœ¨ï¼Œæˆ‘ä»¬è¦å°†æ ¼å¼åŒ–çš„promptä¼ é€’ç»™æˆ‘ä»¬çš„ APIã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "452e9b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55bae99d-7a63-4a40-bab7-de7d10b8ab1b",
   "metadata": {
    "height": 471
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7860\n",
      "Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# å®šä¹‰ä¸€ä¸ªå‡½æ•°ï¼Œç”¨äºæ ¼å¼åŒ–èŠå¤©æç¤ºã€‚\n",
    "def format_chat_prompt(message, chat_history):\n",
    "    # åˆå§‹åŒ–ä¸€ä¸ªç©ºå­—ç¬¦ä¸²ï¼Œç”¨äºå­˜æ”¾æ ¼å¼åŒ–åçš„èŠå¤©æç¤ºã€‚\n",
    "    prompt = \"\"\n",
    "    # éå†èŠå¤©å†å²è®°å½•ã€‚\n",
    "    for turn in chat_history:\n",
    "        # ä»èŠå¤©è®°å½•ä¸­æå–ç”¨æˆ·å’Œæœºå™¨äººçš„æ¶ˆæ¯ã€‚\n",
    "        user_message, bot_message = turn\n",
    "        # æ›´æ–°æç¤ºï¼ŒåŠ å…¥ç”¨æˆ·å’Œæœºå™¨äººçš„æ¶ˆæ¯ã€‚\n",
    "        prompt = f\"{prompt}\\nUser: {user_message}\\nAssistant: {bot_message}\"\n",
    "    # å°†å½“å‰çš„ç”¨æˆ·æ¶ˆæ¯ä¹ŸåŠ å…¥åˆ°æç¤ºä¸­ï¼Œå¹¶é¢„ç•™ä¸€ä¸ªä½ç½®ç»™æœºå™¨äººçš„å›å¤ã€‚\n",
    "    prompt = f\"{prompt}\\nUser: {message}\\nAssistant:\"\n",
    "    # è¿”å›æ ¼å¼åŒ–åçš„æç¤ºã€‚\n",
    "    return prompt\n",
    "\n",
    "# å®šä¹‰ä¸€ä¸ªå‡½æ•°ï¼Œç”¨äºç”Ÿæˆæœºå™¨äººçš„å›å¤ã€‚\n",
    "def respond(message, chat_history):\n",
    "    # è°ƒç”¨ä¸Šé¢çš„å‡½æ•°ï¼Œå°†ç”¨æˆ·çš„æ¶ˆæ¯å’ŒèŠå¤©å†å²è®°å½•æ ¼å¼åŒ–ä¸ºä¸€ä¸ªæç¤ºã€‚\n",
    "    formatted_prompt = format_chat_prompt(message, chat_history)\n",
    "    # ä½¿ç”¨clientå¯¹è±¡çš„generateæ–¹æ³•ç”Ÿæˆæœºå™¨äººçš„å›å¤ï¼ˆæ³¨æ„ï¼šclientå¯¹è±¡åœ¨æ­¤ä»£ç ä¸­å¹¶æœªå®šä¹‰ï¼‰ã€‚\n",
    "    bot_message = client.predict(formatted_prompt,\n",
    "                                  max_new_tokens=1024,\n",
    "                                  stop_sequences=[\"\\nUser:\", \"\"])\n",
    "    # å°†ç”¨æˆ·çš„æ¶ˆæ¯å’Œæœºå™¨äººçš„å›å¤åŠ å…¥åˆ°èŠå¤©å†å²è®°å½•ä¸­ã€‚\n",
    "    chat_history.append((message, bot_message))\n",
    "    # è¿”å›ä¸€ä¸ªç©ºå­—ç¬¦ä¸²å’Œæ›´æ–°åçš„èŠå¤©å†å²è®°å½•ï¼ˆè¿™é‡Œçš„ç©ºå­—ç¬¦ä¸²å¯ä»¥æ›¿æ¢ä¸ºçœŸæ­£çš„æœºå™¨äººå›å¤ï¼Œå¦‚æœéœ€è¦æ˜¾ç¤ºåœ¨ç•Œé¢ä¸Šï¼‰ã€‚\n",
    "    return \"\", chat_history\n",
    "\n",
    "# ä¸‹é¢çš„ä»£ç æ˜¯è®¾ç½®Gradioç•Œé¢çš„éƒ¨åˆ†ã€‚\n",
    "\n",
    "# ä½¿ç”¨Gradioçš„BlocksåŠŸèƒ½å®šä¹‰ä¸€ä¸ªä»£ç å—ã€‚\n",
    "with gr.Blocks() as demo:\n",
    "    # åˆ›å»ºä¸€ä¸ªGradioèŠå¤©æœºå™¨äººç»„ä»¶ï¼Œè®¾ç½®å…¶é«˜åº¦ä¸º240ã€‚\n",
    "    chatbot = gr.Chatbot(height=240) \n",
    "    # åˆ›å»ºä¸€ä¸ªæ–‡æœ¬æ¡†ç»„ä»¶ï¼Œç”¨äºè¾“å…¥æç¤ºã€‚\n",
    "    msg = gr.Textbox(label=\"Prompt\")\n",
    "    # åˆ›å»ºä¸€ä¸ªæäº¤æŒ‰é’®ã€‚\n",
    "    btn = gr.Button(\"Submit\")\n",
    "    # åˆ›å»ºä¸€ä¸ªæ¸…é™¤æŒ‰é’®ï¼Œç”¨äºæ¸…é™¤æ–‡æœ¬æ¡†å’ŒèŠå¤©æœºå™¨äººç»„ä»¶çš„å†…å®¹ã€‚\n",
    "    clear = gr.ClearButton(components=[msg, chatbot], value=\"Clear console\")\n",
    "\n",
    "    # è®¾ç½®æŒ‰é’®çš„ç‚¹å‡»äº‹ä»¶ã€‚å½“ç‚¹å‡»æ—¶ï¼Œè°ƒç”¨ä¸Šé¢å®šä¹‰çš„respondå‡½æ•°ï¼Œå¹¶ä¼ å…¥ç”¨æˆ·çš„æ¶ˆæ¯å’ŒèŠå¤©å†å²è®°å½•ï¼Œç„¶åæ›´æ–°æ–‡æœ¬æ¡†å’ŒèŠå¤©æœºå™¨äººç»„ä»¶ã€‚\n",
    "    btn.click(respond, inputs=[msg, chatbot], outputs=[msg, chatbot])\n",
    "    # è®¾ç½®æ–‡æœ¬æ¡†çš„æäº¤äº‹ä»¶ï¼ˆå³æŒ‰ä¸‹Enteré”®æ—¶ï¼‰ã€‚åŠŸèƒ½ä¸ä¸Šé¢çš„æŒ‰é’®ç‚¹å‡»äº‹ä»¶ç›¸åŒã€‚\n",
    "    msg.submit(respond, inputs=[msg, chatbot], outputs=[msg, chatbot]) \n",
    "\n",
    "# å…³é—­æ‰€æœ‰å·²ç»å­˜åœ¨çš„Gradioå®ä¾‹ã€‚\n",
    "gr.close_all()\n",
    "# å¯åŠ¨æ–°çš„Gradioåº”ç”¨ï¼Œè®¾ç½®åˆ†äº«åŠŸèƒ½ä¸ºTrueï¼Œå¹¶ä½¿ç”¨ç¯å¢ƒå˜é‡PORT3æŒ‡å®šæœåŠ¡å™¨ç«¯å£ã€‚\n",
    "# demo.launch(share=True, server_port=int(os.environ['PORT3']))\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e45875a-8ca4-4124-982e-f2ee6c6e597a",
   "metadata": {},
   "source": [
    "![animal](images/ch06_animal.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022bb649-868d-453d-95e4-fef9cb1feadd",
   "metadata": {},
   "source": [
    "![animal_in_context](images/ch06_animal_in_context.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dae2ad9",
   "metadata": {
    "height": 30
   },
   "source": [
    "ç°åœ¨ï¼Œæˆ‘ä»¬çš„èŠå¤©æœºå™¨äººåº”è¯¥å¯ä»¥å›ç­”åç»­é—®é¢˜äº†ã€‚\n",
    "æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œæˆ‘ä»¬å‘å®ƒå‘é€äº†ä¸Šä¸‹æ–‡ã€‚æˆ‘ä»¬å‘å®ƒå‘é€äº†ä¿¡æ¯ï¼Œç„¶åè¦æ±‚å®ƒå®Œæˆã€‚ä¸€æ—¦æˆ‘ä»¬è¿›å…¥å¦ä¸€ä¸ªè¿­ä»£å¾ªç¯ï¼Œæˆ‘ä»¬å°±ä¼šå‘å®ƒå‘é€æˆ‘ä»¬çš„æ•´ä¸ªä¸Šä¸‹æ–‡ï¼Œç„¶åè¦æ±‚å®ƒå®Œæˆã€‚è¿™å¾ˆé…·ã€‚ä½†æ˜¯ï¼Œå¦‚æœæˆ‘ä»¬ä¸€ç›´è¿™æ ·è¿­ä»£ä¸‹å»ï¼Œé‚£ä¹ˆæ¨¡å‹åœ¨ä¸€æ¬¡å¯¹è¯ä¸­æ‰€èƒ½æ¥å—çš„ä¿¡æ¯é‡å°±ä¼šè¾¾åˆ°æé™ï¼Œå› ä¸ºæˆ‘ä»¬æ€»æ˜¯ç»™å®ƒè¶Šæ¥è¶Šå¤šçš„ä¹‹å‰å¯¹è¯çš„å†…å®¹ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250fcfff",
   "metadata": {
    "height": 46
   },
   "source": [
    "ä¸ºäº†è®©æ¨¡å‹å‘æŒ¥æœ€å¤§ä½œç”¨ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨è¿™é‡Œå°†æœ€å¤§tokenæ•°`max_new_tokens`è®¾ç½®ä¸º 1024ã€ è¿™æ˜¯æˆ‘ä»¬åœ¨ API ä¸­è¿è¡Œçš„ç¡¬ä»¶æ¡ä»¶ä¸‹ï¼Œè¯¥æ¨¡å‹æ‰€èƒ½æ¥å—çš„æœ€å¤§å€¼ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14b9d8d",
   "metadata": {
    "height": 64
   },
   "source": [
    "å¯ä»¥å°è¯•ä»¥ä¸‹promptï¼š\n",
    "1. å“ªäº›åŠ¨ç‰©ç”Ÿæ´»åœ¨çƒ­å¸¦è‰åŸï¼Ÿ\n",
    "2. è¿™ä¹‹ä¸­å“ªç§åŠ¨ç‰©æœ€å¼ºå£®ï¼Ÿ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ded928f",
   "metadata": {
    "height": 30
   },
   "source": [
    "è¿™é‡Œï¼Œæˆ‘ä»¬åˆ›å»ºäº†ä¸€ä¸ªç®€å•ä½†åŠŸèƒ½å¼ºå¤§çš„ç”¨æˆ·ç•Œé¢ï¼Œç”¨äºä¸LLMèŠå¤©ã€‚å¦‚æœéœ€è¦è¿›ä¸€æ­¥Gradio æ‰€èƒ½æä¾›çš„æœ€ä½³åŠŸèƒ½ï¼Œæˆ‘ä»¬å¯ä»¥åˆ›å»ºä¸€ä¸ªåŒ…å«æ›´å¤šåŠŸèƒ½çš„ç”¨æˆ·ç•Œé¢ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b69830",
   "metadata": {
    "height": 30
   },
   "source": [
    "### æ·»åŠ å…¶ä»–é«˜çº§åŠŸèƒ½"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09873dfd-5b6c-41d6-9479-12e8c8894295",
   "metadata": {
    "height": 828
   },
   "outputs": [],
   "source": [
    "# å®šä¹‰ä¸€ä¸ªå‡½æ•°ï¼Œç”¨äºæ ¼å¼åŒ–èŠå¤©æç¤ºã€‚\n",
    "def format_chat_prompt(message, chat_history, instruction):\n",
    "    # åˆå§‹åŒ–æç¤ºï¼ŒåŠ å…¥ç³»ç»ŸæŒ‡ä»¤ã€‚\n",
    "    prompt = f\"System:{instruction}\"\n",
    "    # éå†èŠå¤©å†å²è®°å½•ã€‚\n",
    "    for turn in chat_history:\n",
    "        # ä»èŠå¤©è®°å½•ä¸­æå–ç”¨æˆ·å’Œæœºå™¨äººçš„æ¶ˆæ¯ã€‚\n",
    "        user_message, bot_message = turn\n",
    "        # æ›´æ–°æç¤ºï¼ŒåŠ å…¥ç”¨æˆ·å’Œæœºå™¨äººçš„æ¶ˆæ¯ã€‚\n",
    "        prompt = f\"{prompt}\\nUser: {user_message}\\nAssistant: {bot_message}\"\n",
    "    # å°†å½“å‰çš„ç”¨æˆ·æ¶ˆæ¯ä¹ŸåŠ å…¥åˆ°æç¤ºä¸­ï¼Œå¹¶é¢„ç•™ä¸€ä¸ªä½ç½®ç»™æœºå™¨äººçš„å›å¤ã€‚\n",
    "    prompt = f\"{prompt}\\nUser: {message}\\nAssistant:\"\n",
    "    # è¿”å›æ ¼å¼åŒ–åçš„æç¤ºã€‚\n",
    "    return prompt\n",
    "\n",
    "# å®šä¹‰ä¸€ä¸ªå‡½æ•°ï¼Œç”¨äºç”Ÿæˆæœºå™¨äººçš„å›å¤ã€‚\n",
    "def respond(message, chat_history, instruction, temperature=0.7):\n",
    "    # è°ƒç”¨ä¸Šé¢çš„å‡½æ•°ï¼Œå°†ç”¨æˆ·çš„æ¶ˆæ¯ã€èŠå¤©å†å²è®°å½•å’Œç³»ç»ŸæŒ‡ä»¤æ ¼å¼åŒ–ä¸ºä¸€ä¸ªæç¤ºã€‚\n",
    "    prompt = format_chat_prompt(message, chat_history, instruction)\n",
    "    # æ›´æ–°èŠå¤©å†å²è®°å½•ï¼Œå…ˆåŠ å…¥ç”¨æˆ·çš„æ¶ˆæ¯ï¼ˆæœºå™¨äººçš„å›å¤éƒ¨åˆ†å…ˆä¸ºç©ºï¼‰ã€‚\n",
    "    chat_history = chat_history + [[message, \"\"]]\n",
    "    # ä½¿ç”¨clientå¯¹è±¡çš„generate_streamæ–¹æ³•ç”Ÿæˆæœºå™¨äººçš„å›å¤ï¼ˆæ³¨æ„ï¼šclientå¯¹è±¡åœ¨æ­¤ä»£ç ä¸­å¹¶æœªå®šä¹‰ï¼‰ã€‚\n",
    "    stream = client.generate_stream(prompt,\n",
    "                                    max_new_tokens=1024,\n",
    "                                    stop_sequences=[\"\\nUser:\", \"\"], \n",
    "                                    temperature=temperature)  # è®¾ç½®ç”Ÿæˆå›å¤çš„æ¸©åº¦ï¼Œå†³å®šå›å¤çš„éšæœºæ€§ã€‚\n",
    "    acc_text = \"\"\n",
    "    # ä½¿ç”¨æµå¼å¤„ç†è·å–æœºå™¨äººçš„å›å¤ã€‚\n",
    "    for idx, response in enumerate(stream):\n",
    "        text_token = response.token.text\n",
    "\n",
    "        # å¦‚æœæœ‰ä»»ä½•è¯¦æƒ…ä¿¡æ¯ï¼Œç›´æ¥è¿”å›ã€‚\n",
    "        if response.details:\n",
    "            return\n",
    "\n",
    "        # å¦‚æœæ˜¯ç¬¬ä¸€ä¸ªä»¤ç‰Œå¹¶ä¸”å®ƒä»¥ç©ºæ ¼å¼€å§‹ï¼Œåˆ™å»é™¤è¯¥ç©ºæ ¼ã€‚\n",
    "        if idx == 0 and text_token.startswith(\" \"):\n",
    "            text_token = text_token[1:]\n",
    "\n",
    "        # ç´¯ç§¯ç”Ÿæˆçš„æ–‡æœ¬ã€‚\n",
    "        acc_text += text_token\n",
    "        # æ›´æ–°æœ€åä¸€è½®çš„èŠå¤©è®°å½•ã€‚\n",
    "        last_turn = list(chat_history.pop(-1))\n",
    "        last_turn[-1] += acc_text\n",
    "        chat_history = chat_history + [last_turn]\n",
    "        yield \"\", chat_history\n",
    "        acc_text = \"\"\n",
    "\n",
    "# è®¾ç½®Gradioç•Œé¢éƒ¨åˆ†ã€‚\n",
    "with gr.Blocks() as demo:\n",
    "    # åˆ›å»ºä¸€ä¸ªGradioèŠå¤©æœºå™¨äººç»„ä»¶ï¼Œå¹¶è®¾ç½®å…¶é«˜åº¦ã€‚\n",
    "    chatbot = gr.Chatbot(height=240)\n",
    "    # åˆ›å»ºä¸€ä¸ªæ–‡æœ¬æ¡†ç»„ä»¶ï¼Œç”¨äºè¾“å…¥æç¤ºã€‚\n",
    "    msg = gr.Textbox(label=\"Prompt\")\n",
    "    # åˆ›å»ºä¸€ä¸ªå¯æŠ˜å ç»„ä»¶ï¼Œç”¨äºæ˜¾ç¤ºé«˜çº§é€‰é¡¹ã€‚\n",
    "    with gr.Accordion(label=\"Advanced options\", open=False):\n",
    "        # åœ¨å¯æŠ˜å ç»„ä»¶å†…åˆ›å»ºä¸€ä¸ªæ–‡æœ¬æ¡†ï¼Œç”¨äºè¾“å…¥ç³»ç»Ÿæ¶ˆæ¯ã€‚\n",
    "        system = gr.Textbox(label=\"System message\", lines=2, value=\"ä¸€æ®µç”¨æˆ·å’ŒåŸºäºå¤§è¯­è¨€æ¨¡å‹çš„æ³•å¾‹åŠ©æ‰‹çš„å¯¹è¯. åŠ©æ‰‹ä¼šç»™å‡ºçœŸå®ä¸”æœ‰å¸®åŠ©çš„å›ç­”.\")\n",
    "        # åˆ›å»ºä¸€ä¸ªæ»‘å—ï¼Œç”¨äºè°ƒæ•´å›å¤çš„æ¸©åº¦ã€‚\n",
    "        temperature = gr.Slider(label=\"temperature\", minimum=0.1, maximum=1, value=0.7, step=0.1)\n",
    "    # åˆ›å»ºä¸€ä¸ªæäº¤æŒ‰é’®ã€‚\n",
    "    btn = gr.Button(\"Submit\")\n",
    "    # åˆ›å»ºä¸€ä¸ªæ¸…é™¤æŒ‰é’®ï¼Œç”¨äºæ¸…é™¤æ–‡æœ¬æ¡†å’ŒèŠå¤©æœºå™¨äººç»„ä»¶çš„å†…å®¹ã€‚\n",
    "    clear = gr.ClearButton(components=[msg, chatbot], value=\"Clear console\")\n",
    "\n",
    "    # è®¾ç½®æŒ‰é’®çš„ç‚¹å‡»äº‹ä»¶ã€‚å½“ç‚¹å‡»æ—¶ï¼Œè°ƒç”¨ä¸Šé¢å®šä¹‰çš„respondå‡½æ•°ï¼Œå¹¶ä¼ å…¥ç”¨æˆ·çš„æ¶ˆæ¯ã€èŠå¤©å†å²è®°å½•å’Œç³»ç»Ÿæ¶ˆæ¯ï¼Œç„¶åæ›´æ–°æ–‡æœ¬æ¡†å’ŒèŠå¤©æœºå™¨äººç»„ä»¶ã€‚\n",
    "    btn.click(respond, inputs=[msg, chatbot, system], outputs=[msg, chatbot])\n",
    "    # è®¾ç½®æ–‡æœ¬æ¡†çš„æäº¤äº‹ä»¶ï¼ˆå³æŒ‰ä¸‹Enteré”®æ—¶ï¼‰ã€‚åŠŸèƒ½ä¸ä¸Šé¢çš„æŒ‰é’®ç‚¹å‡»äº‹ä»¶ç›¸åŒã€‚\n",
    "    msg.submit(respond, inputs=[msg, chatbot, system], outputs=[msg, chatbot])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf44cb6-c55c-45eb-8aca-c60f08aa1e0f",
   "metadata": {},
   "source": [
    "![law_1](images/ch06_law_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70256e38-a97f-4375-9083-720571c6cc2c",
   "metadata": {},
   "source": [
    "![law_2](images/ch06_law_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e821c9-f568-4cf5-92b9-dee9f19a45d8",
   "metadata": {},
   "source": [
    "![law_3](images/ch06_law_3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776a928b-1620-4bb0-ab80-0c78ad47b96d",
   "metadata": {},
   "source": [
    "åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬æœ‰é«˜çº§é€‰é¡¹ï¼ŒåŒ…æ‹¬ç³»ç»Ÿæ¶ˆæ¯ï¼Œå®ƒå¯ä»¥è®¾ç½® LLM ä¸ä½ èŠå¤©çš„æ¨¡å¼ã€‚\n",
    "å› æ­¤ï¼Œåœ¨ç³»ç»Ÿæ¶ˆæ¯ä¸­ï¼Œä½ å¯ä»¥è¯´ï¼Œä¾‹å¦‚ï¼Œä½ æ˜¯ä¸€ä¸ªä¹äºåŠ©äººçš„åŠ©æ‰‹ï¼Œæˆ–è€…ä½ å¯ä»¥ç»™å®ƒä¸€ä¸ªç‰¹å®šçš„è¯­æ°”ï¼Œä¸€ä¸ªç‰¹å®šçš„è¯­è°ƒï¼Œ\n",
    "ä½ å¸Œæœ›å®ƒæ›´æœ‰è¶£ä¸€ç‚¹ï¼Œæ›´ä¸¥è‚ƒä¸€ç‚¹ï¼Œä½ çœŸçš„å¯ä»¥åå¤è°ƒè¯•ç³»ç»Ÿæ¶ˆæ¯æç¤ºï¼Œçœ‹çœ‹å®ƒå¯¹ä½ çš„æ¶ˆæ¯æœ‰ä»€ä¹ˆå½±å“ã€‚\n",
    "\n",
    "æœ‰äº›äººç”šè‡³ä¼šæƒ³ç»™ LLM ä¸€ä¸ªè§’è‰²ï¼Œæ¯”å¦‚ä½ æ˜¯ä¸€ä¸ªæä¾›æ³•å¾‹å»ºè®®çš„å¾‹å¸ˆï¼Œæˆ–è€…ä½ æ˜¯ä¸€ä¸ªæä¾›åŒ»ç–—å»ºè®®çš„åŒ»ç”Ÿï¼Œ\n",
    "ä½†è¦æ³¨æ„çš„æ˜¯ï¼Œä¼—æ‰€å‘¨çŸ¥ï¼ŒLLM ä¼šä»¥ä¸€ç§å¬èµ·æ¥å¾ˆçœŸå®çš„æ–¹å¼æä¾›è™šå‡ä¿¡æ¯ã€‚\n",
    "å› æ­¤ï¼Œå°½ç®¡ä½¿ç”¨Falcon 40B è¿›è¡Œå®éªŒå’Œæ¢ç´¢ä¼šå¾ˆæœ‰è¶£ï¼Œä½†åœ¨ç°å®ä¸–ç•Œçš„åº”ç”¨åœºæ™¯ä¸­ï¼Œå¿…é¡»ä¸ºæ­¤ç±»ä½¿ç”¨æ¡ˆä¾‹åˆ¶å®šè¿›ä¸€æ­¥çš„ä¿éšœæªæ–½ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e0e822-ec15-4cfe-9bfe-e90250fbd85e",
   "metadata": {},
   "source": [
    "è¿˜æœ‰å…¶ä»–é«˜çº§å‚æ•°ï¼Œæ¯”å¦‚è¿™é‡Œçš„æ¸©åº¦ã€‚\n",
    "æ¸©åº¦åŸºæœ¬ä¸Šå°±æ˜¯ä½ å¸Œæœ›æ¨¡å‹çš„å˜åŒ–ç¨‹åº¦ã€‚å› æ­¤ï¼Œå¦‚æœå°†æ¸©åº¦è®¾ä¸ºé›¶ï¼Œæ¨¡å‹å°±ä¼šå€¾å‘äºå§‹ç»ˆå¯¹ç›¸åŒçš„è¾“å…¥åšå‡ºç›¸åŒçš„ååº”ã€‚\n",
    "æ‰€ä»¥åŒæ ·çš„é—®é¢˜ï¼ŒåŒæ ·çš„ç­”æ¡ˆã€‚æ¸©åº¦è¶Šé«˜ï¼Œä¿¡æ¯çš„å˜åŒ–å°±è¶Šå¤šã€‚ä½†å¦‚æœæ¸©åº¦è¿‡é«˜ï¼Œå®ƒå°±ä¼šå¼€å§‹ç»™å‡ºæ— æ„ä¹‰çš„ç­”æ¡ˆã€‚\n",
    "å› æ­¤ï¼Œ0.7 æ˜¯ä¸€ä¸ªä¸é”™çš„é»˜è®¤å‚æ•°ï¼Œä½†æˆ‘ä»¬é¼“åŠ±ä½ å¤šåšå°è¯•ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183d7964",
   "metadata": {
    "height": 30
   },
   "source": [
    "é™¤æ­¤ä¹‹å¤–ï¼Œè¿™ä¸ªç”¨æˆ·ç•Œé¢è¿˜èƒ½è®©æˆ‘ä»¬è¿›è¡Œæµå¼ä¼ è¾“å›å¤ã€‚\n",
    "å®ƒé€ä¸ªtokenå‘é€ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°å®ƒå®æ—¶å®Œæˆã€‚å› æ­¤ï¼Œæˆ‘ä»¬ä¸éœ€è¦ç­‰åˆ°æ•´ä¸ªç­”æ¡ˆéƒ½å‡†å¤‡å¥½äº†ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°å®ƒæ˜¯å¦‚ä½•å®Œæˆçš„ã€‚å¦‚æœä½ ä¸ç†è§£è¿™é‡Œçš„æ‰€æœ‰å†…å®¹ï¼Œä¹Ÿä¸ç”¨æ‹…å¿ƒï¼Œå› ä¸ºæˆ‘ä»¬çš„ç›®çš„æ˜¯ç”¨ä¸€ä¸ªéå¸¸å®Œæ•´çš„ç”¨æˆ·ç•Œé¢æ¥ç»“æŸè¯¾ç¨‹ï¼Œå¹¶æä¾›LLMæ–¹é¢çš„æ‰€æœ‰åŠŸèƒ½ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979cc4b6",
   "metadata": {
    "height": 30
   },
   "source": [
    "åœ¨æ ¼å¼èŠå¤©æç¤ºä¸­ï¼Œä¹Ÿå°±æ˜¯æˆ‘ä»¬ä¹‹å‰ä½¿ç”¨çš„åŠŸèƒ½ä¸­ï¼Œæˆ‘ä»¬æ·»åŠ äº†ä¸€ä¸ªæ–°å…ƒç´ ï¼Œé‚£å°±æ˜¯ç³»ç»ŸæŒ‡ä»¤ã€‚å› æ­¤ï¼Œåœ¨å¼€å§‹ç”¨æˆ·åŠ©æ‰‹å¯¹è¯ä¹‹å‰ï¼Œæˆ‘ä»¬åœ¨ç³»ç»Ÿé¡¶éƒ¨æ·»åŠ äº†ä¸€ä¸ªæŒ‡ä»¤ã€‚å› æ­¤ï¼ŒåŸºæœ¬ä¸Šåœ¨å‘é€ç»™æ¨¡å‹çš„æ¯æ¡ä¿¡æ¯çš„å¼€å¤´ï¼Œéƒ½ä¼šæœ‰æˆ‘ä»¬è®¾ç½®çš„ç³»ç»Ÿä¿¡æ¯ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬è°ƒç”¨æ–‡æœ¬ç”Ÿæˆåº“çš„`generate_stream`å‡½æ•°ã€‚è€Œ `generate_stream`å‡½æ•°çš„ä½œç”¨å°±æ˜¯é€ä¸ªç”Ÿæˆå“åº”æ ‡è®°ã€‚å› æ­¤ï¼Œåœ¨è¿™ä¸ªå¾ªç¯ä¸­ï¼Œå‘ç”Ÿçš„äº‹æƒ…å°±æ˜¯æŒ‰æ ‡è®°ç”Ÿæˆå“åº”æ ‡è®°ï¼Œå°†å…¶æ·»åŠ åˆ°èŠå¤©è®°å½•ä¸­ï¼Œç„¶åå°†å…¶è¿”å›ç»™å‡½æ•°ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d9ec80a-39ad-4f58-b79e-4f413c5074c0",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7860\n"
     ]
    }
   ],
   "source": [
    "# å…³é—­å¯èƒ½å·²ç»å¯åŠ¨çš„ä»»ä½•å…ˆå‰çš„gradioå®ä¾‹\n",
    "gr.close_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96cf21ba",
   "metadata": {},
   "source": [
    "ç°åœ¨æˆ‘ä»¬å¯ä»¥å°†æœ¬åœ°æ•°æ®åº“çš„å†…å®¹æ¥å…¥è¿›æ¥ï¼Œè®© llm é€šè¿‡æœ¬åœ°æ•°æ®åº“è¿›è¡Œå›ç­”ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21aa5b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.document_loaders import PyMuPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from zhipuai_embedding import ZhipuAIEmbeddings\n",
    "\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from zhipuai_llm import ZhipuAILLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d30d71aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "98eec0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_directory = '../docs/chroma/knowledge_base'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a338fd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯¼å…¥æ£€ç´¢å¼é—®ç­”é“¾\n",
    "from langchain.chains import RetrievalQA\n",
    "def chat_with_db(query, chat_history):\n",
    "\n",
    "    llm = ZhipuAILLM(model=\"chatglm_std\")\n",
    "\n",
    "    embedding = ZhipuAIEmbeddings()\n",
    "    vectordb = Chroma(\n",
    "        persist_directory=persist_directory,\n",
    "        embedding_function=embedding\n",
    "    )\n",
    "    # Build prompt\n",
    "    template = \"\"\"ä½¿ç”¨ä»¥ä¸‹ä¸Šä¸‹æ–‡ç‰‡æ®µæ¥å›ç­”æœ€åçš„é—®é¢˜ã€‚å¦‚æœä½ ä¸çŸ¥é“ç­”æ¡ˆï¼Œåªéœ€è¯´ä¸çŸ¥é“ï¼Œä¸è¦è¯•å›¾ç¼–é€ ç­”æ¡ˆã€‚ç­”æ¡ˆæœ€å¤šä½¿ç”¨ä¸‰ä¸ªå¥å­ã€‚å°½é‡ç®€æ˜æ‰¼è¦åœ°å›ç­”ã€‚åœ¨å›ç­”çš„æœ€åä¸€å®šè¦è¯´\"æ„Ÿè°¢æ‚¨çš„æé—®ï¼\"\n",
    "    {context}\n",
    "    é—®é¢˜ï¼š{question}\n",
    "    æœ‰ç”¨çš„å›ç­”ï¼š\"\"\"\n",
    "    QA_CHAIN_PROMPT = PromptTemplate.from_template(template)\n",
    "    # qa_chain = ConversationalRetrievalChain.from_llm(llm, vectordb.as_retriever())\n",
    "    qa_chain = RetrievalQA.from_chain_type(\n",
    "        llm,\n",
    "        retriever=vectordb.as_retriever(),\n",
    "        return_source_documents=True,\n",
    "        chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n",
    "    )\n",
    "    result = qa_chain({\"query\": query, \"context\": chat_history})\n",
    "    \n",
    "    # å°†ç”¨æˆ·çš„æ¶ˆæ¯å’Œæœºå™¨äººçš„å›å¤åŠ å…¥åˆ°èŠå¤©å†å²è®°å½•ä¸­ã€‚\n",
    "    chat_history.append((query, result['result']))\n",
    "    # è¿”å›ä¸€ä¸ªç©ºå­—ç¬¦ä¸²å’Œæ›´æ–°åçš„èŠå¤©å†å²è®°å½•ï¼ˆè¿™é‡Œçš„ç©ºå­—ç¬¦ä¸²å¯ä»¥æ›¿æ¢ä¸ºçœŸæ­£çš„æœºå™¨äººå›å¤ï¼Œå¦‚æœéœ€è¦æ˜¾ç¤ºåœ¨ç•Œé¢ä¸Šï¼‰ã€‚\n",
    "    return \"\", chat_history\n",
    "\n",
    "    # return result['answer'], chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2b8e7c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/zhihu123/Project/other/Tutorial_for_developing_LLM_application/notebook/C7  å‰åç«¯æ­å»º\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "88ccc512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7860\n",
      "Running on local URL:  http://127.0.0.1:7869\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7869/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å‘é‡åº“ä¸­å­˜å‚¨çš„æ•°é‡ï¼š0\n",
      "{'query': 'è¯¾ç¨‹', 'context': []}\n",
      "['query']\n",
      "{'input_documents': [], 'question': 'è¯¾ç¨‹'}\n",
      "['input_documents', 'question']\n",
      "{'question': 'è¯¾ç¨‹', 'context': ''}\n",
      "['context', 'question']\n"
     ]
    }
   ],
   "source": [
    "# ä½¿ç”¨Gradioçš„BlocksåŠŸèƒ½å®šä¹‰ä¸€ä¸ªä»£ç å—ã€‚\n",
    "with gr.Blocks() as demo:\n",
    "    # åˆ›å»ºä¸€ä¸ªGradioèŠå¤©æœºå™¨äººç»„ä»¶ï¼Œè®¾ç½®å…¶é«˜åº¦ä¸º240ã€‚\n",
    "    chatbot = gr.Chatbot(height=240) \n",
    "    # åˆ›å»ºä¸€ä¸ªæ–‡æœ¬æ¡†ç»„ä»¶ï¼Œç”¨äºè¾“å…¥æç¤ºã€‚\n",
    "    msg = gr.Textbox(label=\"Prompt\")\n",
    "    # åˆ›å»ºä¸€ä¸ªæäº¤æŒ‰é’®ã€‚\n",
    "    btn = gr.Button(\"Submit\")\n",
    "    # åˆ›å»ºä¸€ä¸ªæ¸…é™¤æŒ‰é’®ï¼Œç”¨äºæ¸…é™¤æ–‡æœ¬æ¡†å’ŒèŠå¤©æœºå™¨äººç»„ä»¶çš„å†…å®¹ã€‚\n",
    "    clear = gr.ClearButton(components=[msg, chatbot], value=\"Clear console\")\n",
    "\n",
    "    # è®¾ç½®æŒ‰é’®çš„ç‚¹å‡»äº‹ä»¶ã€‚å½“ç‚¹å‡»æ—¶ï¼Œè°ƒç”¨ä¸Šé¢å®šä¹‰çš„ chat_with_db å‡½æ•°ï¼Œå¹¶ä¼ å…¥ç”¨æˆ·çš„æ¶ˆæ¯å’ŒèŠå¤©å†å²è®°å½•ï¼Œç„¶åæ›´æ–°æ–‡æœ¬æ¡†å’ŒèŠå¤©æœºå™¨äººç»„ä»¶ã€‚\n",
    "    btn.click(chat_with_db, inputs=[msg, chatbot], outputs=[msg, chatbot])\n",
    "    # è®¾ç½®æ–‡æœ¬æ¡†çš„æäº¤äº‹ä»¶ï¼ˆå³æŒ‰ä¸‹Enteré”®æ—¶ï¼‰ã€‚åŠŸèƒ½ä¸ä¸Šé¢çš„æŒ‰é’®ç‚¹å‡»äº‹ä»¶ç›¸åŒã€‚\n",
    "    msg.submit(chat_with_db, inputs=[msg, chatbot], outputs=[msg, chatbot]) \n",
    "\n",
    "# å…³é—­æ‰€æœ‰å·²ç»å­˜åœ¨çš„Gradioå®ä¾‹ã€‚\n",
    "gr.close_all()\n",
    "# å¯åŠ¨æ–°çš„Gradioåº”ç”¨ï¼Œè®¾ç½®åˆ†äº«åŠŸèƒ½ä¸ºTrueï¼Œå¹¶ä½¿ç”¨ç¯å¢ƒå˜é‡PORT3æŒ‡å®šæœåŠ¡å™¨ç«¯å£ã€‚\n",
    "# demo.launch(share=True, server_port=int(os.environ['PORT3']))\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56f070c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a19761b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
